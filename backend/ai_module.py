import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import json
import os

class AIDebugger:
    def __init__(self):
        # Load knowledge base of common errors and solutions
        self.knowledge_base = self._load_knowledge_base()
        
        # Initialize TF-IDF vectorizer
        self.vectorizer = TfidfVectorizer(stop_words='english')
        
        # Fit vectorizer on knowledge base texts
        texts = [item['error_pattern'] for item in self.knowledge_base]
        if texts:
            self.vectorizer.fit(texts)
    
    def _load_knowledge_base(self):
        # In a real application, this would load from a database
        # Here we're using a simple in-memory list
        return [
            {
                "error_pattern": "database connection failed timeout connection refused",
                "error_type": "Database Connection",
                "probable_cause": "Database server is down or network issue",
                "suggestion": "1. Check if the database server is running\n2. Verify database credentials\n3. Check network connectivity\n4. Ensure firewall allows the connection"
            },
            {
                "error_pattern": "memory usage high out of memory heap space",
                "error_type": "Memory Issue",
                "probable_cause": "Application is consuming too much memory",
                "suggestion": "1. Increase memory allocation\n2. Check for memory leaks\n3. Optimize memory-intensive operations\n4. Consider implementing pagination for large data sets"
            },
            {
                "error_pattern": "null pointer exception nullpointerexception null reference",
                "error_type": "Null Reference",
                "probable_cause": "Attempting to access a null object reference",
                "suggestion": "1. Add null checks before accessing objects\n2. Initialize variables properly\n3. Use Optional/Maybe pattern for potentially null values\n4. Review the stack trace to identify the exact line causing the issue"
            },
            {
                "error_pattern": "authentication failed unauthorized invalid credentials",
                "error_type": "Authentication",
                "probable_cause": "Invalid user credentials or expired session",
                "suggestion": "1. Verify username and password\n2. Check if the user account is locked\n3. Ensure authentication service is running\n4. Check for expired tokens or sessions"
            },
            {
                "error_pattern": "timeout request timed out connection timeout",
                "error_type": "Timeout",
                "probable_cause": "Service is taking too long to respond",
                "suggestion": "1. Check service health\n2. Increase timeout threshold\n3. Optimize the slow operation\n4. Implement circuit breaker pattern for unreliable services"
            },
            {
                "error_pattern": "file not found no such file or directory",
                "error_type": "File I/O",
                "probable_cause": "Required file is missing or inaccessible",
                "suggestion": "1. Verify file path is correct\n2. Check file permissions\n3. Ensure the file exists\n4. Create the file if it's supposed to be generated by the application"
            },
            {
                "error_pattern": "syntax error invalid syntax unexpected token",
                "error_type": "Syntax Error",
                "probable_cause": "Code contains syntax errors",
                "suggestion": "1. Check for missing brackets, quotes, or semicolons\n2. Verify proper indentation\n3. Look for typos in keywords\n4. Use a linter to identify syntax issues"
            },
            {
                "error_pattern": "cpu usage high cpu load",
                "error_type": "Performance",
                "probable_cause": "Inefficient code or resource-intensive operations",
                "suggestion": "1. Profile the application to identify bottlenecks\n2. Optimize algorithms with high complexity\n3. Consider caching frequently accessed data\n4. Implement background processing for heavy tasks"
            }
        ]
    
    def analyze_error(self, log_entry):
        """Analyze an error log and suggest possible solutions"""
        # Extract relevant text from the log entry
        error_text = self._extract_error_text(log_entry)
        
        if not error_text:
            return {
                "error_type": "Unknown",
                "probable_cause": "Could not determine the cause from the log",
                "suggestion": "Review the complete log for more details",
                "confidence": 0.0
            }
        
        # Find the most similar error in the knowledge base
        best_match, confidence = self._find_best_match(error_text)
        
        if best_match and confidence > 0.3:
            return {
                "error_type": best_match["error_type"],
                "probable_cause": best_match["probable_cause"],
                "suggestion": best_match["suggestion"],
                "confidence": float(confidence)
            }
        else:
            # Fallback to simple keyword matching
            return self._keyword_analysis(log_entry)
    
    def _extract_error_text(self, log_entry):
        """Extract relevant text from a log entry for analysis"""
        text_parts = []
        
        # Add message
        if 'message' in log_entry:
            text_parts.append(log_entry['message'])
        
        # Add details
        if 'details' in log_entry:
            text_parts.append(log_entry['details'])
        
        # Add stack trace if available
        if 'stack_trace' in log_entry:
            # Clean up stack trace - remove line numbers and paths
            clean_trace = re.sub(r'at [\w\.]+\([\w\.]+:\d+\)', '', log_entry['stack_trace'])
            text_parts.append(clean_trace)
        
        return ' '.join(text_parts).lower()
    
    def _find_best_match(self, error_text):
        """Find the most similar error in the knowledge base using TF-IDF and cosine similarity"""
        if not self.knowledge_base:
            return None, 0.0
        
        try:
            # Transform the error text
            error_vector = self.vectorizer.transform([error_text])
            
            # Transform all knowledge base entries
            kb_vectors = self.vectorizer.transform([item['error_pattern'] for item in self.knowledge_base])
            
            # Calculate similarities
            similarities = cosine_similarity(error_vector, kb_vectors)[0]
            
            # Find the best match
            best_idx = np.argmax(similarities)
            confidence = similarities[best_idx]
            
            return self.knowledge_base[best_idx], confidence
        except Exception as e:
            print(f"Error in similarity calculation: {e}")
            return None, 0.0
    
    def _keyword_analysis(self, log_entry):
        """Simple keyword-based analysis as fallback"""
        message = log_entry.get('message', '').lower()
        details = log_entry.get('details', '').lower()
        combined_text = message + ' ' + details
        
        if 'database' in combined_text or 'connection' in combined_text:
            return {
                "error_type": "Database Issue",
                "probable_cause": "Database connectivity problem",
                "suggestion": "Check database connection settings and ensure the database server is running",
                "confidence": 0.5
            }
        elif 'memory' in combined_text:
            return {
                "error_type": "Memory Issue",
                "probable_cause": "Memory leak or insufficient resources",
                "suggestion": "Increase memory allocation or check for memory leaks",
                "confidence": 0.5
            }
        elif 'timeout' in combined_text or 'timed out' in combined_text:
            return {
                "error_type": "Timeout",
                "probable_cause": "Network latency or service unavailability",
                "suggestion": "Check network connectivity and service health",
                "confidence": 0.5
            }
        elif 'authentication' in combined_text or 'unauthorized' in combined_text:
            return {
                "error_type": "Authentication",
                "probable_cause": "Authentication failure",
                "suggestion": "Verify user credentials and permissions",
                "confidence": 0.5
            }
        else:
            return {
                "error_type": "Unknown Error",
                "probable_cause": "Could not determine from available information",
                "suggestion": "Review application logs for more details",
                "confidence": 0.3
            }
    
    def save_feedback(self, log_id, analysis_id, was_helpful, user_comments=None):
        """Save user feedback on analysis to improve future suggestions"""
        # In a real application, this would save to a database
        feedback = {
            "log_id": log_id,
            "analysis_id": analysis_id,
            "was_helpful": was_helpful,
            "user_comments": user_comments,
            "timestamp": "2025-11-10T10:00:00.000000"  # In real app, use current timestamp
        }
        
        # Here we just print it, but in a real app we would save it
        print(f"Received feedback: {json.dumps(feedback)}")
        return True